[{"authors":null,"categories":null,"content":"I am a Ph.D. student at the GRAIL Lab and Geometric Learning Lab at Northeastern University, co-advised by Lawson Wong and Robin Walters. I received my B.S. and M.S. at KAIST and researched prediction models for complex semiconductor tools. Before coming to Northeastern, I worked as a software engineer and systems administrator at Samsung Electronics. Previously I\u0026rsquo;ve worked on multiresolution tensor models for spatial modeling and on using generative models as priors for inverse imaging problems. I am currently interested in model-based reinforcement learning and how to use equivariant neural networks effectively for efficient learning.\n","date":1663977600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1663977600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a Ph.D. student at the GRAIL Lab and Geometric Learning Lab at Northeastern University, co-advised by Lawson Wong and Robin Walters. I received my B.S. and M.S. at KAIST and researched prediction models for complex semiconductor tools.","tags":null,"title":"Jung Yeon Park","type":"authors"},{"authors":["Jung Yeon Park","Lawson L.S. Wong"],"categories":[],"content":"","date":1663977600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663977600,"objectID":"36c34d01902b6a58d5a8421ace6b4b80","permalink":"https://jypark0.github.io/publication/2022-neurips-bmil/","publishdate":"2022-09-24T00:00:00Z","relpermalink":"/publication/2022-neurips-bmil/","section":"publication","summary":"Behavior cloning of expert demonstrations can speed up learning optimal policies in a more sample-efficient way over reinforcement learning. However, the policy cannot extrapolate well to unseen states outside of the demonstration data, creating covariate shift (agent drifting away from demonstrations) and compounding errors. In this work, we tackle this issue by extending the region of attraction around the demonstrations so that the agent can learn how to get back onto the demonstrated trajectories if it veers off-course. We train a generative backward dynamics model and generate short imagined trajectories from states in the demonstrations. By imitating both demonstrations and these model rollouts, the agent learns both the demonstrated paths and how to get back on to these paths. With optimal or near-optimal demonstrations, the learned policy will be both optimal and robust to deviations, with a wider region of attraction. On continuous control domains, we evaluate the robustness when starting from different initial states unseen in the demonstration data. While both our method and other imitation learning baselines can successfully solve the tasks for initial states in the training distribution, our method exhibits considerably more robustness to different initial states.","tags":[],"title":"Robust Imitation Learning of a Few Demonstrations with a Backwards Model","type":"publication"},{"authors":["Jung Yeon Park","Ondrej Biza","Linfeng Zhao","Jan Willem van de Meent","Robin Walters"],"categories":[],"content":"","date":1658102400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658102400,"objectID":"3be3346aac40d4561f392c215801e7fe","permalink":"https://jypark0.github.io/publication/2022-icml-sen/","publishdate":"2022-07-18T00:00:00Z","relpermalink":"/publication/2022-icml-sen/","section":"publication","summary":"Incorporating symmetries can lead to highly data-efficient and generalizable models by defining equivalence classes of data samples related by transformations. However, characterizing how transformations act on input data is often difficult, limiting the applicability of equivariant models. We propose learning symmetric embedding networks (SENs) that encode an input space (e.g. images), where we do not know the effect of transformations (e.g. rotations), to a feature space that transforms in a known manner under these operations. This network can be trained end-to-end with an equivariant task network to learn an explicitly symmetric representation. We validate this approach in the context of equivariant transition models with 3 distinct forms of symmetry. Our experiments demonstrate that SENs facilitate the application of equivariant networks to data with complex symmetry representations. Moreover, doing so can yield improvements in accuracy and generalization relative to both fully-equivariant and non-equivariant baselines.","tags":[],"title":"Learning Symmetric Embedding Networks for Equivariant World Models","type":"publication"},{"authors":["Jung Yeon Park","Niklas Smedemark-Margulies","Max Daniels","Rose Yu","Jan-Willem van de Meent","Paul Hand"],"categories":null,"content":"","date":1603411200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603411200,"objectID":"403727690ffcac95a387da25e52be91b","permalink":"https://jypark0.github.io/publication/2020-neurips-generator/","publishdate":"2020-10-23T00:00:00Z","relpermalink":"/publication/2020-neurips-generator/","section":"publication","summary":"Recent work has explored the use of generator networks with low latent dimension as signal priors for image recovery in compressed sensing. However, the recovery performance of such models is limited by high representation error. We introduce a method to reduce the representation error of such generator signal priors by cutting one or more initial blocks at test time and optimizing over the resulting higher- dimensional latent space. Experiments demonstrate significantly improved recovery for a variety of architectures. This approach also works well for out-of-training- distribution images and is competitive with other state-of-the-art methods. Our experiments show that test-time architectural modifications can greatly improve the recovery quality of generator signal priors for compressed sensing.","tags":[],"title":"Generator Surgery for Compressed Sensing","type":"publication"},{"authors":["Jung Yeon Park","Kenneth Theo Carr","Stephan Zheng","Yisong Yue","Rose Yu"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"19086b3f6609b9b3cee546aa693cd032","permalink":"https://jypark0.github.io/publication/2020-icml-mrtl/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/publication/2020-icml-mrtl/","section":"publication","summary":"Efficient and interpretable spatial analysis is crucial in many fields such as geology, sports, and climate science. Tensor latent factor models can describe higher-order correlations for spatial data. However, they are computationally expensive to train and are sensitive to initialization, leading to spatially incoherent, uninterpretable results. We develop a novel Multiresolution Tensor Learning (MRTL) algorithm for efficiently learning interpretable spatial patterns. MRTL initializes the latent factors from an approximate full-rank tensor model for improved interpretability and progressively learns from a coarse resolution to the fine resolution for boosted efficiency. We also prove the theoretical convergence and computational complexity of MRTL. When applied to two real-world datasets, MRTL demonstrates 4~5x speedup compared to a fixed resolution approach while yielding accurate and interpretable models.","tags":[],"title":"Multiresolution Tensor Learning for Efficient and Interpretable Spatial Analysis","type":"publication"},{"authors":["Hyeong-Ook Kim","Se-Hyeon Park","Jung Yeon Park","James R. Morrison"],"categories":null,"content":"","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575158400,"objectID":"66223be9a70707620467119df85d2a48","permalink":"https://jypark0.github.io/publication/2019-wsc-consequences/","publishdate":"2019-12-01T00:00:00Z","relpermalink":"/publication/2019-wsc-consequences/","section":"publication","summary":"Clustered photography tools (CPTs) are very complex and can substantially influence the throughput of wafer fabrication facilities. Therefore, efficient lot scheduling for CPTs can directly improve fab performance. In this paper, we develop mixed integer linear programs for linear, affine, exit recursion, and flow line models of CPTs to optimize schedules with respect to mean cycle time, makespan, and tardiness. We simulate a true CPT using a flow line and solve the MILPs for other above mentioned, reduced models. Schedules from reduced models are then input into the flow line optimization model in order to evaluate the loss. Using numerical experiments, we show that exit recursion models outperform other models. Under time limits, exit recursion models exhibit at least 6% better performance than flow lines for large problems on cycle time.","tags":[],"title":"On the Consequences of Un-Modeled Dynamics to the Optimality of Schedules in Clustered Photolithography Tools","type":"publication"},{"authors":["James R. Morrison","Jung Yeon Park","Kyungsu Park","Sang Yoon Bae"],"categories":null,"content":"","date":1532995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532995200,"objectID":"ea1da0a0518103584483dd7db19c98f6","permalink":"https://jypark0.github.io/publication/2018-patent-erm/","publishdate":"2018-07-31T00:00:00Z","relpermalink":"/publication/2018-patent-erm/","section":"publication","summary":"","tags":[],"title":"Exit Recursion Models of Clustered Photolithography Tools for Fab Level Simulation","type":"publication"},{"authors":["James R. Morrison","Jung Yeon Park","Kyungsu Park","Sang Yoon Bae"],"categories":null,"content":"","date":1528156800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528156800,"objectID":"5e6f98b42227f0e88997b7e95cdf187a","permalink":"https://jypark0.github.io/publication/2018-patent-models/","publishdate":"2018-06-05T00:00:00Z","relpermalink":"/publication/2018-patent-models/","section":"publication","summary":"","tags":[],"title":"Models of Photolithography Tools for Fab- Level Simulation: From Affine to Flow Line","type":"publication"},{"authors":["Jung Yeon Park","Kyungsu Park","James R. Morrison"],"categories":null,"content":"","date":1509494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509494400,"objectID":"3421150cf29f3d4a505be14743672c83","permalink":"https://jypark0.github.io/publication/2017-tsm-models/","publishdate":"2017-11-01T00:00:00Z","relpermalink":"/publication/2017-tsm-models/","section":"publication","summary":"Fab-level discrete-event simulation is an important practical tool for the analysis and optimization of semiconductor wafer fabricators. In such facilities, a clustered photolithography tool (CPT) is by far the most expensive tool and often the capacity bottleneck. In this paper, we consider linear, affine, flow line, and detailed models of CPTs for use in fab-level simulation. We develop extensions to affine and flow line models and demonstrate exactly how to convert raw CPT data into the various models. Using a detailed CPT model based on industry data as the baseline, numerical experiments are conducted to test the models' fidelity for cycle time, lot residency time, and throughput. We also compare the computational burden of each model class. Further simulations are conducted to test the models' robustness to changing fab conditions, e.g., when lot size or train size changes. Flow line models are shown to be more accurate and robust than linear or affine models and require approximately 200 times less computation than detailed models.","tags":[],"title":"Models of Clustered Photolithography Tools for Fab-Level Simulation: From Affine to Flow Line","type":"publication"},{"authors":["Jung Yeon Park","Kyungsu Park","James R. Morrison"],"categories":null,"content":"","date":1477008e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477008e3,"objectID":"293ab3b9cadc28224cd3fbda13c7f722","permalink":"https://jypark0.github.io/publication/2016-tsm-erm/","publishdate":"2016-10-21T00:00:00Z","relpermalink":"/publication/2016-tsm-erm/","section":"publication","summary":"In semiconductor wafer fabricators (fabs), clustered photolithography tools (CPTs) are often the bottleneck. With a focus on fab-level simulation, we propose a new class of equipment models for CPTs called exit recursion models (ERMs). These models are inspired by concepts from flow line theory. We describe the intuition behind ERMs and provide the parameterization and simulation equations. These ERMs are data-driven empirical models and we develop three types based on different data perspectives: 1) tool log; 2) wafer log; and 3) lot log. To assess the quality of the proposed models, we conduct three classes of simulation experiments. A detailed CPT model, an affine model, and an empirical flow line model are used as the baselines. We consider mean cycle time, lot residency time, throughput time, and computation time as our primary performance metrics. The results suggest that ERMs are more accurate and robust than the affine models for all metrics and sometimes rival the performance of the empirical flow line models considered. ERMs require about 1.9 times as much computation as an affine model and about 250 times less computation than an empirical flow line model. ERMs may be helpful to increase the accuracy of fab-level simulation results without significant additional computation.","tags":[],"title":"Exit Recursion Models of Clustered Photolithography Tools for Fab Level Simulation","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://jypark0.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]